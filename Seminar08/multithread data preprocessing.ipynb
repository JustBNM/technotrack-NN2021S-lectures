{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:80% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<style>.container {width:80% !important;}</style>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, utils\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from queue import Empty, Queue\n",
    "from threading import Thread\n",
    "import threading\n",
    "from torch.autograd import Variable\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "# augmentation library\n",
    "from imgaug.augmentables import Keypoint, KeypointsOnImage\n",
    "import imgaug.augmenters as iaa\n",
    "import accimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "Для того, чтобы было ясно, что происходит в этом коде, нужно сформулировать задачу, для которой запускаются генераторы данных, описываемые ниже.\n",
    "\n",
    "Задача - автокодировщик. Это означает, что целевая переменная совпадает с признаковым описанием объектов. То есть, нейросеть должна выучить идентичное преобразование.\n",
    "\n",
    "А это означает, что результатом генератора данных может быть один массив/батч массивов. Порождать совпадающий с ним массив целевой переменной нет надобности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "use_gpu = True\n",
    "batch_size = 64\n",
    "images_base_dir = '/app/vg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class thread_killer(object):    \n",
    "    \"\"\"Boolean object for signaling a worker thread to terminate\n",
    "    Once a thread is launched, it should be terminated at some moment.\n",
    "    In case the function of this thread is an infinite loop, one needs a mutex\n",
    "    for signaling a worker thread to break the loop.\n",
    "    The fuction will return, and the thread will be terminated.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.to_kill = False\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.to_kill\n",
    "\n",
    "    def set_tokill(self, tokill):\n",
    "        self.to_kill = tokill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threaded_batches_feeder(tokill, batches_queue, dataset_generator):\n",
    "    \"\"\"\n",
    "    Threaded worker for pre-processing input data.\n",
    "    tokill (thread_killer): an object that indicates whether a thread should be terminated\n",
    "    dataset_generator (Dataset): training/validation data generator\n",
    "    batches_queue (Queue): a limited size thread-safe Queue instance for train/validation data batches\n",
    "    \"\"\"\n",
    "    while tokill() == False:\n",
    "        for sample_batch in dataset_generator:\n",
    "            batches_queue.put(torch.Tensor(sample_batch), block=True)\n",
    "            if tokill() == True:\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threaded_cuda_batches(tokill, cuda_batches_queue, batches_queue):\n",
    "    \"\"\"\n",
    "    Thread worker for transferring pytorch tensors into GPU. \n",
    "    batches_queue (Queue): the queue that fetches numpy cpu tensors.\n",
    "    cuda_batches_queue (Queue): the queue receiving numpy cpu tensors and transfering them to GPU memory.\n",
    "    \"\"\"\n",
    "    while tokill() == False:\n",
    "        sample_batch = batches_queue.get(block=True)\n",
    "        sample_batch = Variable(sample_batch).to(device)\n",
    "        cuda_batches_queue.put(sample_batch, block=True)\n",
    "        if tokill() == True:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Threadsafe_iter:\n",
    "    \"\"\"\n",
    "    Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return next(self.it)\n",
    "\n",
    "def get_objects_i(objects_count):\n",
    "    \"\"\"Cyclic generator of paths indices\"\"\"\n",
    "    current_objects_id = 0\n",
    "    while True:\n",
    "        yield current_objects_id\n",
    "        current_objects_id  = (current_objects_id + 1) % objects_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarksDataset(Dataset):\n",
    "    def __init__(self, pkl_file, root_dir, transform=None, batch_size = 8, augment = True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pkl_file (string): Path to the pkl file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            batch_size (int, optional): batch size\n",
    "        \"\"\"\n",
    "        with open(pkl_file, 'rb') as f:\n",
    "            marked_data_loaded = pickle.load(f)\n",
    "        self.landmarks_frame = []\n",
    "        self.total_len = 0\n",
    "        for dicts in marked_data_loaded:\n",
    "            dict_len = len(dicts) \n",
    "            self.total_len += dict_len\n",
    "            if dict_len > 0:\n",
    "                self.landmarks_frame.append(pd.DataFrame(dicts).T)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.objects_id_generator = Threadsafe_iter(get_objects_i(len(self.landmarks_frame)))\n",
    "        \n",
    "        self.lock = threading.Lock()\n",
    "        self.yield_lock = threading.Lock()\n",
    "        self.init_count = 0\n",
    "        self.augment = augment\n",
    "        self.cache = {}\n",
    "        \n",
    "        if self.augment:\n",
    "            # instantiate augmentations\n",
    "            self.seq = iaa.Sequential([iaa.Fliplr(0.5),\n",
    "                                       iaa.Flipud(0.5),\n",
    "                                       iaa.GaussianBlur(sigma=(0, 5)),\n",
    "                                       iaa.Cutout(nb_iterations=(1, 3), size=0.3, squared=False, cval=0),\n",
    "                                       iaa.CoarseDropout((0.0, 0.05), size_percent=(0.02, 0.25)),\n",
    "                                       iaa.Affine(rotate=(-180,180),\n",
    "                                                  translate_percent={'x': (-0.05, 0.05), 'y': (-0.05, 0.05)},\n",
    "                                                  shear={'x': (-10, 10), 'y': (-10, 10)}),\n",
    "                                       iaa.ElasticTransformation(alpha=(0, 5.0), sigma=0.25)],\n",
    "                                      random_order=True)\n",
    "        else:\n",
    "            self.seq = iaa.Identity()       \n",
    "\n",
    "\n",
    "    def __len__(self):                        \n",
    "        return self.total_len\n",
    "    \n",
    "    def shuffle(self):\n",
    "        self.landmarks_frame = shuffle(self.landmarks_frame)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            with self.lock:\n",
    "                if (self.init_count == 0):\n",
    "                    self.shuffle()\n",
    "                    self.imgs = []\n",
    "                    self.init_count = 1\n",
    "            \n",
    "            for obj_id in self.objects_id_generator:\n",
    "                image_set = []\n",
    "                for i in range(6):\n",
    "                    img_name = os.path.join(self.root_dir, self.landmarks_frame[obj_id].iloc[0 , i])\n",
    "                    if img_name in self.cache:\n",
    "                        img = self.cache[img_name]\n",
    "                    else:\n",
    "                        img = accimage.Image(img_name)\n",
    "                        image_np = np.empty([img.channels, img.height, img.width], dtype=np.uint8)      # CxHxW\n",
    "                        img.copyto(image_np)\n",
    "                        self.cache[img_name] = img\n",
    "                    \n",
    "                    img_augmented = self.seq(img)\n",
    "                    \n",
    "                    image_set.append(img_augmented)\n",
    "                image_set = np.concatenate(image_set, axis=-1)\n",
    "                for part_id in range(self.landmarks_frame[obj_id].shape[0]):\n",
    "                    landmarks = self.landmarks_frame[obj_id].iloc[part_id, 6:]\n",
    "                    landmarks = landmarks.to_numpy(int)\n",
    "                    landmarks = landmarks.reshape(-1, 4)\n",
    "\n",
    "                    image = image_set[landmarks[0, 2]: landmarks[0, 3],\n",
    "                                      landmarks[0, 0]: landmarks[0, 1], :]\n",
    "                    image = image.transpose((2, 0, 1))\n",
    "                    image = transform.resize(image, (18, 280, 280))\n",
    "\n",
    "                    # Concurrent access by multiple threads to the lists below\n",
    "                    with self.yield_lock:\n",
    "                        if (len(self.imgs)) < self.batch_size:\n",
    "                            self.imgs.append(image)\n",
    "                        if len(self.imgs) % self.batch_size == 0:\n",
    "                            imgs_f32 = np.float32(self.imgs)\n",
    "                            yield imgs_f32\n",
    "                            self.imgs = []\n",
    "            # At the end of an epoch we re-init data-structures\n",
    "            with self.lock:\n",
    "                self.landmarks_frame = shuffle(self.landmarks_frame)\n",
    "                self.init_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        image = sample\n",
    "        return torch.from_numpy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create the instance of the LandmarksDataset class\n",
    "dataset = LandmarksDataset(pkl_file='./marked_full_data.pkl',\n",
    "                           root_dir=images_base_dir,\n",
    "                           transform=ToTensor(),\n",
    "                           batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sanity check\n",
    "the dataset should generate batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch in dataset:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define the device which will be used to perform a network optimization\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = len(dataset)//batch_size + 1\n",
    "STEPS_PER_EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to training mode\n",
    "# model.train()  \n",
    "\n",
    "# Here we instantiate queues and mutexes, and launch the threads that will preprocess the data and send it into GPU\n",
    "batches_queue_length = min(STEPS_PER_EPOCH, 24)\n",
    "    \n",
    "train_batches_queue = Queue(maxsize=batches_queue_length)\n",
    "train_cuda_batches_queue = Queue(maxsize=10)\n",
    "train_thread_killer = thread_killer()\n",
    "train_thread_killer.set_tokill(False)\n",
    "preprocess_workers = 32\n",
    "\n",
    "for _ in range(preprocess_workers):\n",
    "    thr = Thread(target=threaded_batches_feeder, args=(train_thread_killer, train_batches_queue, dataset))\n",
    "    thr.start()\n",
    "\n",
    "train_cuda_transfers_thread_killer = thread_killer()\n",
    "train_cuda_transfers_thread_killer.set_tokill(False)\n",
    "train_cudathread = Thread(target=threaded_cuda_batches, args=(train_cuda_transfers_thread_killer, train_cuda_batches_queue, train_batches_queue))\n",
    "train_cudathread.start()\n",
    "# Everything is ready for the training\n",
    "\n",
    "print('Training ...')\n",
    "for epoch in range(num_epochs):\n",
    "    num_batches = 0\n",
    "    for image_batch in tqdm(range(STEPS_PER_EPOCH), total=STEPS_PER_EPOCH):\n",
    "        x = train_cuda_batches_queue.get(block=True)\n",
    "        x = x.float()\n",
    "        \n",
    "        # Here one usually implements training steps\n",
    "#         apply model\n",
    "#         y = model(x)\n",
    "#         loss = ...\n",
    "        \n",
    "#         backpropagation\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "        \n",
    "#         one step of the optmizer (using the gradients from backpropagation)\n",
    "#         optimizer.step()\n",
    "        \n",
    "        num_batches += 1\n",
    "    \n",
    "#     scheduler.step()\n",
    "\n",
    "\n",
    "\n",
    "train_thread_killer.set_tokill(True)\n",
    "train_cuda_transfers_thread_killer.set_tokill(True)\n",
    "for _ in range(preprocess_workers):\n",
    "    try:\n",
    "        # Enforcing thread shutdown\n",
    "        train_batches_queue.get(block=True, timeout=1)\n",
    "        train_cuda_batches_queue.get(block=True, timeout=1)\n",
    "    except Empty:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
