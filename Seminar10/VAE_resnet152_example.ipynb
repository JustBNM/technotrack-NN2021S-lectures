{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n",
    "import pickle\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-d latent space, parameter count in same order of magnitude\n",
    "# as in the original VAE paper (VAE paper has about 3x as many)\n",
    "latent_dims = 512\n",
    "capacity = 64\n",
    "variational_beta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def globalAvgPooling(x):\n",
    "    return x.mean(dim=[-2, -1], keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        c = capacity\n",
    "        self.resnet152 = models.resnet152(pretrained=True, progress=False)\n",
    "        for param in self.resnet152.parameters(): # запрещаем обучаться resnet 152\n",
    "            param.requires_grad = False\n",
    "        self.resnet152.fc = torch.nn.Sequential(nn.Linear(in_features=2048, out_features=1024, bias=True),\n",
    "                            nn.ReLU())\n",
    "        self.fc1 = nn.Linear(in_features=1024*6, out_features=1024, bias=True)   \n",
    "        self.fc_mu = nn.Linear(in_features=1024, out_features=latent_dims)\n",
    "        self.fc_logvar = nn.Linear(in_features=1024, out_features=latent_dims)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = torch.split(x, 3, dim=1)      # x.shape: batch_size x 3 x 280 x 280\n",
    "        y = []                       \n",
    "        for img in x:                     # img.shape: batch_size x 3 x 280 x 280\n",
    "            img = self.resnet152(img)     # img.shape: batch_size x 1024\n",
    "            y.append(img)\n",
    "        \n",
    "        x = torch.cat(y, dim=1)           # x.shape: batch_size x 1024*6\n",
    "        x = self.fc1(x)\n",
    "        x_mu = self.fc_mu(x)\n",
    "        x_logvar = self.fc_logvar(x)\n",
    "        return x_mu, x_logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        c = capacity\n",
    "        self.fc = nn.Linear(in_features=latent_dims, out_features=c*4*35*35)\n",
    "        \n",
    "        self.conv_d1 = nn.ConvTranspose2d(in_channels=c*4, out_channels=c*4, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn_d1 = nn.BatchNorm2d(num_features=c*4)\n",
    "        self.conv3 = nn.ConvTranspose2d(in_channels=c*4, out_channels=c*2, kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "        self.conv_d2 = nn.ConvTranspose2d(in_channels=c*2, out_channels=c*2, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn_d2 = nn.BatchNorm2d(num_features=c*2)\n",
    "        self.conv2 = nn.ConvTranspose2d(in_channels=c*2, out_channels=c, kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "        self.conv_d3 = nn.ConvTranspose2d(in_channels=c, out_channels=c, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn_d3 = nn.BatchNorm2d(num_features=c)\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels=c, out_channels=18, kernel_size=4, stride=2, padding=1)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.size(0), capacity*4, 35, 35) # unflatten batch of feature vectors to a batch of multi-channel feature maps\n",
    "        x = F.relu(self.bn_d1(self.conv_d1(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.bn_d2(self.conv_d2(x)))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.bn_d3(self.conv_d3(x)))\n",
    "        x = self.conv1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        latent_mu, latent_logvar = self.encoder(x)\n",
    "        latent = self.latent_sample(latent_mu, latent_logvar)\n",
    "        x_recon = self.decoder(latent)\n",
    "        return x_recon, latent_mu, latent_logvar\n",
    "    \n",
    "    def latent_sample(self, mu, logvar):\n",
    "        if self.training:\n",
    "            # the reparameterization trick\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = torch.empty_like(std).normal_()\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    recon_loss = F.mse_loss(x, recon_x)\n",
    "    \n",
    "    kldivergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return recon_loss, variational_beta * kldivergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
